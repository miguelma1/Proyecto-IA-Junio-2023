{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Junio 2023: Ensamble de modelos predictivos\n",
    "\n",
    "## Autores\n",
    "- Juan Carlos López Veiga\n",
    "- Miguel Manzano Álvarez\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el desarollo de este proyecto se tendran en cuenta para la experimentación los ficheros _titanic.csv_ y _pcos.csv_ ubicados en la carpeta _datos_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar importaremos todo aquello necesario para el desarrollo del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from statistics import mode\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from math import sqrt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, gracias a la librería _pandas_, guardaremos en sus respectivas variables el conjunto de datos iniciales tanto de titanic como de pcos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcosData = pd.read_csv('./datos/pcos.csv', skiprows = 1, header = None,\n",
    "                           names=['Age (yrs)', 'Weight (Kg)', 'Height(Cm)', 'BMI', 'Blood Group', 'Pulse rate(bpm)',\n",
    "                                   'RR (breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)', 'Cycle length(days)', 'Marriage Status (Yrs)',\n",
    "                                     'Pregnant(Y/N)', 'No. of abortions', 'I beta-HCG(mIU/mL)', 'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)',\n",
    "                                       'Waist(inch)', 'Waist:Hip Ratio', 'TSH (mIU/L)', 'PRL(ng/mL)', 'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight gain(Y/N)', 'hair growth(Y/N)',\n",
    "                                         'Skin darkening (Y/N)', 'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)', 'Reg.Exercise(Y/N)', 'BP _Systolic (mmHg)', 'BP _Diastolic (mmHg)', 'Follicle No. (L)',\n",
    "                                           'Follicle No. (R)', 'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'Endometrium (mm)', 'PCOS (Y/N)'])\n",
    "\n",
    "\n",
    "titanicData = pd.read_csv('./datos/titanic.csv', skiprows = 1, header = None,\n",
    "                              names=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Initial', 'Age_band', 'Family_Size', 'Alone', 'Fare_cat', 'Deck', 'Title', 'Is_Married', 'Survived'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función _dataStandarization_ nos ayudará a estandarizar nuestros ficheros de entradas. Los argumentos requeridos por esta función son:\n",
    "- data: Conjunto de datos a estandarizar.\n",
    "- dataName: String que dará nombre a los ficheros resultantes. Por coherencia se recomienta que este sea 'titanic' o 'pcos' en función de los datos con los que se esté trabajando.\n",
    "- excludedColumns: Columnas que se excluiran en el proceso de estandatización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataStandarization (data, dataName, excludedColumns):\n",
    "    if not isinstance (dataName, str):\n",
    "        print(\"El argumento dataName debe ser una cadena de carateres.\")\n",
    "    \n",
    "    elif not isinstance (excludedColumns, list):\n",
    "        print(\"El argumento excludedColumns debe ser una lista con el nombre de las columnas a excluir.\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        data_copy = data.drop(excludedColumns, axis = 1)\n",
    "        numerical_columns = [col for col in data.columns if col not in excludedColumns]\n",
    "        columns_to_standarize = data[numerical_columns]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        columns_to_standarize = scaler.fit_transform(columns_to_standarize)\n",
    "        data[numerical_columns] = columns_to_standarize\n",
    "\n",
    "        data.to_csv('./datos/' + dataName + '_standarized.csv', index = False)\n",
    "\n",
    "        print(\"El nuevo fichero estandarizado se ha guardado en el directorio datos con el nombre \" + dataName + \"_standarized.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, definiremos aquellas columnas que excluiremos en el proceso de estandarización, en este caso, las variables objetivo y las variables _booleanas_, y procederemos a estandarizar los ficheros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El nuevo fichero estandarizado se ha guardado en el directorio datos con el nombre titanic_standarized.csv\n",
      "El nuevo fichero estandarizado se ha guardado en el directorio datos con el nombre pcos_standarized.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_excluded = ['Sex', 'Alone', 'Is_Married', 'Survived']\n",
    "pcos_excluded = ['Pregnant(Y/N)', 'Weight gain(Y/N)', 'hair growth(Y/N)', 'Skin darkening (Y/N)', 'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)','Reg.Exercise(Y/N)', 'PCOS (Y/N)']\n",
    "\n",
    "dataStandarization(titanicData, 'titanic', titanic_excluded)\n",
    "dataStandarization(pcosData, 'pcos', pcos_excluded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función _dataSplit_ dividirá el fichero de entrada en un fichero de entrenamiento (2/3 del fichero original) y en un fichero de pruebas (1/3 del fichero original). Para ello requerirá los sigueintes argumentos:\n",
    "- data: Conjunto de datos a estandarizar.\n",
    "- dataName: String que dará nombre a los ficheros resultantes. Por coherencia se recomienta que este sea 'titanic' o 'pcos' en función de los datos con los que se esté trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit (data, dataName):\n",
    "    if not isinstance (dataName, str):\n",
    "        print(\"El argumento dataName debe ser una cadena de carateres.\")\n",
    "    \n",
    "    else:\n",
    "        data_train, data_test = model_selection.train_test_split(data, test_size = 0.3, random_state = 99)\n",
    "        data_train.to_csv('./datos/' + dataName + '_train.csv', index = False)\n",
    "        data_test.to_csv('./datos/' + dataName + '_test.csv', index = False)\n",
    "\n",
    "        print('Las dimensiones originales de los datos de entrada son: ', data.shape)\n",
    "        print('El conjunto de entrenamiento se ha guardado en el directorio datos con el nombre ' + dataName + '_train.csv, y sus dimensiones son: ', data_train.shape)\n",
    "        print('El conjunto de pruebas se ha guardado en el directorio datos con el nombre ' + dataName + '_test.csv, y sus dimensiones son: ', data_test.shape)\n",
    "        return data_train, data_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida dicha función, procedemos a crear nuestros nuevos ficheros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones originales de los datos de entrada son:  (891, 16)\n",
      "El conjunto de entrenamiento se ha guardado en el directorio datos con el nombre titanic_train.csv, y sus dimensiones son:  (623, 16)\n",
      "El conjunto de pruebas se ha guardado en el directorio datos con el nombre titanic_test.csv, y sus dimensiones son:  (268, 16)\n",
      "Las dimensiones originales de los datos de entrada son:  (541, 40)\n",
      "El conjunto de entrenamiento se ha guardado en el directorio datos con el nombre pcos_train.csv, y sus dimensiones son:  (378, 40)\n",
      "El conjunto de pruebas se ha guardado en el directorio datos con el nombre pcos_test.csv, y sus dimensiones son:  (163, 40)\n"
     ]
    }
   ],
   "source": [
    "titanicTrain, titanicTest = dataSplit(titanicData, 'titanic')\n",
    "pcosTrain, pcosTest = dataSplit(pcosData, 'pcos')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estas alturas ya tenemos dos ficheros por cada conjunto inicial de datos, el de entrenamiento y el de pruebas. Sin embargo, procederemos a aplicar las técnicas _Bootstrapping_ y _Random Subspace Method_ al fichero de entrenamiento para así obtener nuevos conjuntos de datos con los que entrenar los diferentes modelos.\n",
    "\n",
    "La función generadorConjuntosEntrenamiento necesitará los siguientes argumentos:\n",
    "- fileName: String que dará nombre a los ficheros resultantes. Por coherencia se recomienta que este sea 'titanic' o 'pcos' en función de los datos con los que se esté trabajando.\n",
    "- data: Conjunto de datos de entrenamiento.\n",
    "- amountFiles: El número total de nuevos ficheros creados será igual a _amountFiles_ x _amountFiles_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generadorConjutosEntrenamiento(fileName, data, amountFiles):\n",
    "\n",
    "    bFiles = sqrt(amountFiles)\n",
    "    rsmFiles = sqrt(amountFiles)\n",
    "\n",
    "    res= [] \n",
    "\n",
    "    col = data[data.columns[:-1]]\n",
    "    \n",
    "    objectiveVariable = data.loc[:, data.columns == data.columns[-1]]\n",
    "\n",
    "    numCol=col.shape[1]\n",
    "\n",
    "    for i in range (amountFiles):\n",
    "        bootstrap_sample = data.sample(frac = 0.8, replace = True) \n",
    "        for j in range (amountFiles):    \n",
    "            \n",
    "            selcted_column = np.random.choice(numCol,size=int(np.sqrt(numCol)),replace = False)\n",
    "            subspace_sample = col.iloc[:, selcted_column].copy() \n",
    "            subspace_sample[data.columns.values[-1]] = objectiveVariable\n",
    "\n",
    "            res.append(subspace_sample)\n",
    "\n",
    "            route = f'./datos/conjuntosEntrenamiento/{fileName}_trainSet_{i+1}.{j+1}.csv'\n",
    "            subspace_sample.to_csv(route, index = False)\n",
    "            print('Fichero creados en la ruta: ', route)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definiremos la función encargada del entrenamiento de modelos, la cual llamará a la función generadora definida previamente. Para ello definiremos previamente una función que nos será útil para dividir las variables objetivos del resto de variables.\n",
    "\n",
    "También definiremos dos funciones, una que dada una lista de listas de valores, nos devuelva una lista con las modas de los valores de la misma posición, y otra que dado una lista de modelos entrenados y un conjuto de datos, nos prediga el valor de la variable objetivo utilizando la moda de los resultdos obtenidos en cada uno de los modelos.\n",
    "\n",
    "A continuación definiremos las siguientes funciones:\n",
    "- separarVariables: Dado un conjunto de datos, separa la variable objetivo del resto de variables.\n",
    "- entrenamientoDeModelos: Algoritmo encargado de entrenar una serie de modelos a partir de un conjunto de entrenamiento, para ello necesitara diferentes argumentos:\n",
    "    - data: Conjunto de datos de entrenamiento.\n",
    "    - numModelos: Numero de modelos a entrenar, debido a als técnicas aplicadas, el resultado final de modelos es igual a numModelos * numModelos.\n",
    "    - algoritmo: Argumento de tipo String, de valor \"TREE\" o \"SGD\" en función del algoritmo deseado para el entrenamiento de los modelos.\n",
    "    - proporcionColumnas: Numero entre 0 y 1 que representa el porcentaje de columnas empleadas para el entrenamiento de los modelos.\n",
    "    - fileName: String que representa el nombre del archivo, para seguir la coherencia del proyecto, esta será \"titanic\" o \"pcos\" en función del conjunto de datos.\n",
    "- modasLista: Dada una lista de listas de numeros, devuelve una lista con las modas de los numeros de una misma posición.\n",
    "- algoritmoPrediccion: A partir de unos datos de pruebas y una lista de modelos, predice el valor de la variable objetivo. Estas predicciones se basan en la moda del conjunto de modelos previamente entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separarVariables(data):\n",
    "    x = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def entrenamientoDeModelos(data, numModelos, algoritmo, proporcionColumnas, fileName):\n",
    "    res = []\n",
    "\n",
    "    if not 0 <= proporcionColumnas <= 1:\n",
    "        print(\"El parametro proporcionColumnas debe ser un numero entre 0 y 1\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        if not isinstance(algoritmo, str): \n",
    "            print(\"El argumento algoritmo no es un String\")\n",
    "    \n",
    "        else:\n",
    "\n",
    "            training_data = generadorConjutosEntrenamiento(fileName, data, numModelos)\n",
    "\n",
    "            for i in training_data:\n",
    "\n",
    "                if algoritmo.upper() == 'TREE':\n",
    "                    alg = DecisionTreeClassifier()\n",
    "        \n",
    "                elif  algoritmo.upper() == 'SGD':\n",
    "                    alg = SGDClassifier()\n",
    "\n",
    "                x, y = separarVariables(i)\n",
    "\n",
    "                num_columns = int(proporcionColumnas * x.shape[1])\n",
    "                selected_columns = np.random.choice(x.columns, size=num_columns, replace=False)\n",
    "               \n",
    "                selectedX = x[selected_columns]\n",
    "\n",
    "                alg.fit(selectedX, y)\n",
    "\n",
    "                res.append((alg,selectedX.columns))\n",
    "    return res\n",
    "\n",
    "def modasLista(list_of_lists):\n",
    "    result = []\n",
    "    list_length = len(list_of_lists[0])\n",
    "\n",
    "    for i in range(list_length):\n",
    "        elements = [lst[i] for lst in list_of_lists]    \n",
    "        result.append(mode(elements))\n",
    "\n",
    "    return result\n",
    "\n",
    "def algoritmoPrediccion(datosTesteo, conjunto):\n",
    "    ls = []\n",
    "    for i in conjunto:\n",
    "        pred = i[0].predict(datosTesteo[i[1]])\n",
    "        ls.append(pred)\n",
    "    return  modasLista(ls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definidos nuestros algoritmos, procederemos a probar con unos ejemplos. Para ello llamaremos a las funciones definidas anteriormente, introduciendoles diferentes parámetros de entrada y obteniendo una lista de modelos para _titanic_ y otra para _pcos_ que nos ayudarán a hacer las predicciones correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_1.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_1.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_1.3.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_2.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_2.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_2.3.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_3.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_3.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/titanic_trainSet_3.3.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_1.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_1.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_1.3.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_1.4.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_2.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_2.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_2.3.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_2.4.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_3.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_3.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_3.3.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_3.4.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_4.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_4.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_4.3.csv\n",
      "Fichero creados en la ruta:  ./datos/conjuntosEntrenamiento/pcos_trainSet_4.4.csv\n"
     ]
    }
   ],
   "source": [
    "titanicModels = entrenamientoDeModelos(titanicTrain, 3, 'tree', 1, 'titanic')\n",
    "pcosModels = entrenamientoDeModelos(pcosTrain, 4, 'tree', 1, 'pcos')\n",
    "\n",
    "titanicPredictions = algoritmoPrediccion(titanicTest, titanicModels)\n",
    "pcosPredictions = algoritmoPrediccion(pcosTest, pcosModels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el rendimiento de nuestros modelos nos fijaremos en dos métricas:\n",
    "- Puntuación de precisión equilibrada: Promedio de la precisión de cada clase individual.\n",
    "- F1: Media del equilibrio entre la precisión y el recall (tasa de verdaderos positivos y falsos negativos) del modelo.\n",
    "Ambas métricas son proporcionadas por la librería _sklearn_, sin embargo, para facilitar su implementación se han definido sus respectivas funciones que requieren los siguientes argumentos de entrada:\n",
    "- testingData: Conjunto de datos de pruebas (considerando unos datos de prueba de los que conocemos previamente la clasificación del mismo).\n",
    "- predicted: Lista de valores que represente la calsificación del conjunto de pruebas realizada por los modelos entrenados.\n",
    "\n",
    "En estas métricas, el valor óptimo sera 1 y el peor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def balancedAccuracyScore(testingData, predicted):\n",
    "    return balanced_accuracy_score(testingData.iloc[:,-1].tolist(), predicted)\n",
    "\n",
    "def f1Score(testingData, predicted):\n",
    "    return f1_score(testingData.iloc[:,-1].tolist(), predicted)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente observaremos los valores de las métricas del ejemplo de experimento realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de la métrica Puntuación de precisión equilibrada para el conjunto de pruebas de titanic es:  0.7501834189288334\n",
      "El valor de la métrica Puntuación de precisión equilibrada para el conjunto de pruebas de pcos es:  0.7689649630343941\n",
      "El valor de la métrica F1 para el conjunto de pruebas de titanic es:  0.6741573033707866\n",
      "El valor de la métrica F1 para el conjunto de pruebas de pcos es:  0.7047619047619049\n"
     ]
    }
   ],
   "source": [
    "print(\"El valor de la métrica Puntuación de precisión equilibrada para el conjunto de pruebas de titanic es: \", balancedAccuracyScore(titanicTest, titanicPredictions))\n",
    "print(\"El valor de la métrica Puntuación de precisión equilibrada para el conjunto de pruebas de pcos es: \", balancedAccuracyScore(pcosTest, pcosPredictions))\n",
    "\n",
    "print(\"El valor de la métrica F1 para el conjunto de pruebas de titanic es: \", f1Score(titanicTest, titanicPredictions))\n",
    "print(\"El valor de la métrica F1 para el conjunto de pruebas de pcos es: \", f1Score(pcosTest, pcosPredictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
