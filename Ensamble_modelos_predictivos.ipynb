{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero leemos los ficheros iniciales de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcosData = pd.read_csv('./datos/pcos.csv', skiprows = 1, header = None,\n",
    "                           names=['Age (yrs)', 'Weight (Kg)', 'Height(Cm)', 'BMI', 'Blood Group', 'Pulse rate(bpm)',\n",
    "                                   'RR (breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)', 'Cycle length(days)', 'Marriage Status (Yrs)',\n",
    "                                     'Pregnant(Y/N)', 'No. of abortions', 'I beta-HCG(mIU/mL)', 'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)',\n",
    "                                       'Waist(inch)', 'Waist:Hip Ratio', 'TSH (mIU/L)', 'PRL(ng/mL)', 'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight gain(Y/N)', 'hair growth(Y/N)',\n",
    "                                         'Skin darkening (Y/N)', 'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)', 'Reg.Exercise(Y/N)', 'BP _Systolic (mmHg)', 'BP _Diastolic (mmHg)', 'Follicle No. (L)',\n",
    "                                           'Follicle No. (R)', 'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'Endometrium (mm)', 'PCOS (Y/N)'])\n",
    "\n",
    "\n",
    "titanicData = pd.read_csv('./datos/titanic.csv', skiprows = 1, header = None,\n",
    "                              names=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Initial', 'Age_band', 'Family_Size', 'Alone', 'Fare_cat', 'Deck', 'Title', 'Is_Married', 'Survived'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion para estandarizar los ficheros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataStandarization (data, dataName, excludedColumns):\n",
    "    if not isinstance (dataName, str):\n",
    "        print(\"El argumento dataName debe ser una cadena de carateres.\")\n",
    "    \n",
    "    elif not isinstance (excludedColumns, list):\n",
    "        print(\"El argumento excludedColumns debe ser una lista con el nombre de las columnas a excluir.\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        data_copy = data.drop(excludedColumns, axis = 1)\n",
    "        numerical_columns = [col for col in data.columns if col not in excludedColumns]\n",
    "        columns_to_standarize = data[numerical_columns]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        columns_to_standarize = scaler.fit_transform(columns_to_standarize)\n",
    "        data[numerical_columns] = columns_to_standarize\n",
    "\n",
    "        data.to_csv('./datos/' + dataName + '_standarized.csv', index = False)\n",
    "\n",
    "        print(\"El nuevo fichero estandarizado se ha guardado en el directorio datos con el nombre \" + dataName + \".csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las columnas que no vamos a considerar para la estandarización, en este caso las columnas booleanas y las columnas resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El nuevo fichero estandarizado se ha guardado en el directorio datos con el nombre titanic.csv\n",
      "El nuevo fichero estandarizado se ha guardado en el directorio datos con el nombre pcos.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_excluded = ['Sex', 'Alone', 'Is_Married', 'Survived']\n",
    "pcos_excluded = ['Pregnant(Y/N)', 'Weight gain(Y/N)', 'hair growth(Y/N)', 'Skin darkening (Y/N)', 'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)','Reg.Exercise(Y/N)', 'PCOS (Y/N)']\n",
    "\n",
    "dataStandarization(titanicData, 'titanic', titanic_excluded)\n",
    "dataStandarization(pcosData, 'pcos', pcos_excluded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación dividiremos los ficheros estandarizados en dos, uno para el conjunto de entrenamiento y otro para el conjunto de prueba. Para ello definiremos la función necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit (data, dataName):\n",
    "    if not isinstance (dataName, str):\n",
    "        print(\"El argumento dataName debe ser una cadena de carateres.\")\n",
    "    \n",
    "    else:\n",
    "        data_train, data_test = model_selection.train_test_split(data, test_size = 0.3, random_state = 99)\n",
    "        data_train.to_csv('./datos/' + dataName + '_train.csv', index = False)\n",
    "        data_test.to_csv('./datos/' + dataName + '_test.csv', index = False)\n",
    "\n",
    "        print('Las dimensiones originales de los datos de entrada son: ', data.shape)\n",
    "        print('El conjunto de entrenamiento se ha guardado en el directorio datos con el nombre ' + dataName + '_train.csv, y sus dimensiones son: ', data_train.shape)\n",
    "        print('El conjunto de pruebas se ha guardado en el directorio datos con el nombre ' + dataName + '_test.csv, y sus dimensiones son: ', data_test.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente creamos los dos conjuntos de datos a partir del fichero estandarizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones originales de los datos de entrada son:  (891, 16)\n",
      "El conjunto de entrenamiento se ha guardado en el directorio datos con el nombre titanic_train.csv, y sus dimensiones son:  (623, 16)\n",
      "El conjunto de pruebas se ha guardado en el directorio datos con el nombre titanic_test.csv, y sus dimensiones son:  (268, 16)\n",
      "Las dimensiones originales de los datos de entrada son:  (541, 40)\n",
      "El conjunto de entrenamiento se ha guardado en el directorio datos con el nombre pcos_train.csv, y sus dimensiones son:  (378, 40)\n",
      "El conjunto de pruebas se ha guardado en el directorio datos con el nombre pcos_test.csv, y sus dimensiones son:  (163, 40)\n"
     ]
    }
   ],
   "source": [
    "dataSplit(titanicData, 'titanic')\n",
    "dataSplit(pcosData, 'pcos')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez estandarizados los ficheros de entrenamientos, definiremos una función para que, dado un conjunto de datos, se generen diferentes conjuntos de datos de entrenamiento aplicando primero la técnica de Bootstrapping y más adelante Rndom Subspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generadorConjutosEntrenamiento(fileName, data, amountFiles):\n",
    "\n",
    "    res= [] #lista de conjuntos de entrenamientos\n",
    "\n",
    "    col = data[data.columns[:-1]]# cogemos todas las columnas salvo la ultima \n",
    "    \n",
    "    objectiveVariable = data.loc[:, data.columns == data.columns[-1]] #guardamos la ultima columna\n",
    "\n",
    "    numCol=col.shape[1] #dimension de la columna en col\n",
    "\n",
    "    #hacemos bootstrapping\n",
    "    for i in range (amountFiles):\n",
    "        bootstrap_sample = data.sample(frac = 0.5, replace = True) \n",
    "        #para cada subset consideramos solo la mitad de los datos de entrada y con posibilidad de repeticion\n",
    "        for j in range (amountFiles): #para cada nuevo archivo bootstrappeado\n",
    "            #cogemos una serie de columnas aleatorias    \n",
    "            selcted_column=np.random.choice(numCol,size=int(np.sqrt(numCol)),replace=False)#seleccionamos un subconjunto de columnas \n",
    "            subspace_sample = col.iloc[:, selcted_column].copy()#creamos un nuevo DataSet \n",
    "            #-----------------------------A LO MEJOR HAY QUE CAMBIARLO---------------\n",
    "            subspace_sample[data.columns.values[-1]] = objectiveVariable #añadimos columna survived\n",
    "            #------------------------------------------------------------------------\n",
    "\n",
    "            res.append(subspace_sample)\n",
    "\n",
    "            route = f'./datos/conjutosEntrenamiento/{fileName}_trainSet_{i+1}.{j+1}.csv'\n",
    "            subspace_sample.to_csv(route, index = False)\n",
    "            print('Fichero creados en la ruta: ', route)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último ejecutamos la función para ambos ficheros originales de entrenamiento, entroduciendo \"titanic\" y \"pcos\" respectivamente como \"fileName\" para mantener la coherencia de nombres en los archivos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/titanic_trainSet_1.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/titanic_trainSet_1.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/titanic_trainSet_2.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/titanic_trainSet_2.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/pcos_trainSet_1.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/pcos_trainSet_1.2.csv\n",
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/pcos_trainSet_2.1.csv\n",
      "Fichero creados en la ruta:  ./datos/conjutosEntrenamiento/pcos_trainSet_2.2.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[     Vit D3 (ng/mL)  hair growth(Y/N)  LH(mIU/mL)  Marriage Status (Yrs)  \\\n",
       " 0         -0.094875                 0   -0.032219              -0.141744   \n",
       " 1          0.032913                 0   -0.062129               0.692452   \n",
       " 2         -0.000624                 0   -0.064554               0.483903   \n",
       " 3         -0.047749                 0   -0.047462              -0.767391   \n",
       " 4         -0.017682                 0   -0.064323              -1.393038   \n",
       " ..              ...               ...         ...                    ...   \n",
       " 536       -0.038498                 0   -0.053814               0.066805   \n",
       " 537       -0.077817                 0   -0.041919              -0.767391   \n",
       " 538       -0.079263                 0   -0.042612               0.066805   \n",
       " 539       -0.079552                 0   -0.024712              -1.184489   \n",
       " 540       -0.094007                 1   -0.025059              -1.184489   \n",
       " \n",
       "      Pulse rate(bpm)       BMI  PCOS (Y/N)  \n",
       " 0           1.073680 -1.236018           0  \n",
       " 1           0.169968  0.146227           0  \n",
       " 2          -0.281888  0.244959           1  \n",
       " 3          -0.281888  1.331009           0  \n",
       " 4          -0.281888 -1.038555           0  \n",
       " ..               ...       ...         ...  \n",
       " 536        -0.281888 -1.433482           0  \n",
       " 537        -0.281888  0.244959           0  \n",
       " 538         0.169968 -0.224017           0  \n",
       " 539         0.169968 -0.520213           0  \n",
       " 540         1.525536  1.429740           1  \n",
       " \n",
       " [541 rows x 7 columns],\n",
       "      Weight gain(Y/N)  Pulse rate(bpm)  LH(mIU/mL)  hair growth(Y/N)  \\\n",
       " 0                   0         1.073680   -0.032219                 0   \n",
       " 1                   0         0.169968   -0.062129                 0   \n",
       " 2                   0        -0.281888   -0.064554                 0   \n",
       " 3                   0        -0.281888   -0.047462                 0   \n",
       " 4                   0        -0.281888   -0.064323                 0   \n",
       " ..                ...              ...         ...               ...   \n",
       " 536                 0        -0.281888   -0.053814                 0   \n",
       " 537                 1        -0.281888   -0.041919                 0   \n",
       " 538                 0         0.169968   -0.042612                 0   \n",
       " 539                 0         0.169968   -0.024712                 0   \n",
       " 540                 1         1.525536   -0.025059                 1   \n",
       " \n",
       "      FSH(mIU/mL)  Height(Cm)  PCOS (Y/N)  \n",
       " 0      -0.030679   -0.744005           0  \n",
       " 1      -0.036306    0.831983           0  \n",
       " 2      -0.041794    1.412610           1  \n",
       " 3      -0.030172   -1.407579           0  \n",
       " 4      -0.048989    0.749036           0  \n",
       " ..           ...         ...         ...  \n",
       " 536    -0.020947    1.344925           0  \n",
       " 537    -0.043962    0.251356           0  \n",
       " 538    -0.012184   -0.744005           0  \n",
       " 539    -0.047052   -1.075792           0  \n",
       " 540    -0.048943    1.412610           1  \n",
       " \n",
       " [541 rows x 7 columns],\n",
       "      PRG(ng/mL)  RR (breaths/min)  Blood Group  Follicle No. (L)  \\\n",
       " 0     -0.010760          1.633608     0.651284         -0.740617   \n",
       " 1      0.094356          0.448119     0.651284         -0.740617   \n",
       " 2     -0.065946         -0.737370    -1.523682          1.626032   \n",
       " 3     -0.065946          0.448119    -0.436199         -0.977282   \n",
       " 4     -0.060690         -0.737370    -1.523682         -0.740617   \n",
       " ..          ...               ...          ...               ...   \n",
       " 536   -0.094852         -1.922858     1.738766         -1.213947   \n",
       " 537   -0.094852         -0.737370     0.651284          0.679373   \n",
       " 538   -0.094852          0.448119    -0.436199         -1.213947   \n",
       " 539   -0.094852          0.448119     0.651284          0.206043   \n",
       " 540   -0.063318          0.448119    -0.436199          0.679373   \n",
       " \n",
       "      Hair loss(Y/N)  Avg. F size (R) (mm)  PCOS (Y/N)  \n",
       " 0                 0              0.768537           0  \n",
       " 1                 0             -0.437816           0  \n",
       " 2                 1              1.371714           1  \n",
       " 3                 0             -0.437816           0  \n",
       " 4                 1             -0.437816           0  \n",
       " ..              ...                   ...         ...  \n",
       " 536               0             -1.644169           0  \n",
       " 537               0              0.768537           0  \n",
       " 538               0             -1.945757           0  \n",
       " 539               0              0.165361           0  \n",
       " 540               1              0.768537           1  \n",
       " \n",
       " [541 rows x 7 columns],\n",
       "      Height(Cm)  Endometrium (mm)  FSH(mIU/mL)  No. of abortions  Age (yrs)  \\\n",
       " 0     -0.744005          0.011133    -0.030679         -0.416737  -0.634606   \n",
       " 1      0.831983         -2.207618    -0.036306         -0.416737   0.845230   \n",
       " 2      1.412610          0.704493    -0.041794         -0.416737   0.290291   \n",
       " 3     -1.407579         -0.451107    -0.030172         -0.416737   1.030210   \n",
       " 4      0.749036         -0.682227    -0.048989         -0.416737  -1.189545   \n",
       " ..          ...               ...          ...               ...        ...   \n",
       " 536    1.344925         -0.820899    -0.020947          1.028486   0.660251   \n",
       " 537    0.251356         -0.127539    -0.043962          1.028486  -0.264647   \n",
       " 538   -0.744005         -0.543555    -0.012184         -0.416737   0.845230   \n",
       " 539   -1.075792          1.397853    -0.047052         -0.416737  -0.819586   \n",
       " 540    1.412610         -0.728451    -0.048943         -0.416737  -1.559504   \n",
       " \n",
       "           BMI  PCOS (Y/N)  \n",
       " 0   -1.236018           0  \n",
       " 1    0.146227           0  \n",
       " 2    0.244959           1  \n",
       " 3    1.331009           0  \n",
       " 4   -1.038555           0  \n",
       " ..        ...         ...  \n",
       " 536 -1.433482           0  \n",
       " 537  0.244959           0  \n",
       " 538 -0.224017           0  \n",
       " 539 -0.520213           0  \n",
       " 540  1.429740           1  \n",
       " \n",
       " [541 rows x 7 columns]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generadorConjutosEntrenamiento('titanic', titanicData, 2)\n",
    "generadorConjutosEntrenamiento('pcos', pcosData, 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
